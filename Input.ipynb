{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier_path = \"haarcascade_frontalface_default.xml\"\n",
    "face_classifier = cv.CascadeClassifier(face_classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(image):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    else:\n",
    "        for face in faces:\n",
    "            (x, y, w, h) = face\n",
    "            croped_image = image[y : y + h, x : x + w]\n",
    "            \n",
    "        return croped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n"
     ]
    }
   ],
   "source": [
    "sample_path = \"Samples/\"\n",
    "n_sample = 500\n",
    "count = 0\n",
    "device = 0\n",
    "capture = cv.VideoCapture(device)\n",
    "\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    croped_image = face_extractor(frame)\n",
    "    \n",
    "    if croped_image is not None:\n",
    "        resized = cv.resize(croped_image, (128, 128))\n",
    "        gray = cv.cvtColor(resized, cv.COLOR_BGR2GRAY)\n",
    "        cv.imwrite(sample_path + str(count) + '.jpg', gray)\n",
    "        cv.putText(croped_image, str(count), (25,25), cv.FONT_HERSHEY_PLAIN, 1, (255, 50, 50), 2)\n",
    "        count += 1\n",
    "    else:\n",
    "        print(\"Face Not Found\")\n",
    "        croped_image = np.zeros(shape = (256, 256, 3), dtype = np.int16)\n",
    "        \n",
    "    cv.imshow('Result', croped_image)\n",
    "    \n",
    "    if cv.waitKey(1) == 13 or count == n_sample:\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_2] *",
   "language": "python",
   "name": "conda-env-tensorflow_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
